## 1.1. Оценка трудоёмкости методом трёх точек (PERT)

**Цель оценки.**  
Мы оцениваем трудоёмкость разработки MVP сервиса FrameFinder – мобильного приложения и бэкенда, 
позволяющих распознавать фильм по кадру или короткому клипу и выводить карточку фильма (название, год, жанр, описание, актёры) с ссылками «где смотреть». 
Состав работ сформирован на основе анализа конкурентов и целевого TO BE-процесса 
(вход: изображение/клип, обработка на бэкенде, распознавание моделью CV/ML, обогащение метаданными и ссылками, логирование и дообучение модели).

### 1.1.1. Перечень оцениваемых задач

| ID | Задача                                       | Краткое описание |
|----|----------------------------------------------|------------------|
| 1  | Уточнение требований и MVP                   | Формализация базового функционала (распознавание, карточка фильма, мобильный клиент и т.д.). |
| 2  | Пользовательские сценарии AS IS / TO BE      | Описание текущих и целевых потоков, B2B-контекста. |
| 3  | Проектирование архитектуры                   | Связка клиент – бэкенд – ML – базы метаданных – агрегаторы «где смотреть». |
| 4  | Сбор и подготовка датасета кадров            | Источники кадров, разметка, связь с фильмами и актёрами. |
| 5  | Разработка и обучение базовой ML-модели      | CV/ML-модель, первая версия, дообучение на hard cases. |
| 6  | Бэкенд-сервис распознавания и обогащения     | API, поиск в базе кадров, выдача карточки фильма. |
| 7  | Интеграция с агрегаторами «где смотреть»     | Подключение JustWatch/Кинопоиска и аналогов. |
| 8  | Мобильное приложение                         | Загрузка кадра/клипа, экран результата, история/избранное, шаринг. |
| 9  | Минимальный B2B API и метрики                | Endpoint для партнёров, нормализация идентификаторов, отчётность и SLA. |
| 10 | Тестирование, релиз и поддержка              | Функциональное тестирование, обработка ошибок, запуск MVP. |

### 1.1.2. Сбор независимых индивидуальных оценок

Каждый член команды независимо оценивал длительность каждой задачи тремя
параметрами:
- оптимистичная оценка O (в днях),
- наиболее вероятная оценка M,
- пессимистичная оценка P.

Оценки собирались в индивидуальные таблицы, без предварительного обсуждения
конкретных чисел, чтобы избежать эффекта якоря и группового давления.

### 1.1.3. Расчёт ожидаемой длительности задач

Для каждой задачи и для каждого участника рассчитывалась ожидаемая длительность Te
по формуле PERT:

Te = (O + 4·M + P) / 6.

Затем для каждой задачи бралась средняя Te по всем участникам как итоговая оценка.

Итоговые оценки по задачам приведены в таблице ниже:

| ID | Задача                          | O_avg | M_avg | P_avg | Te_avg |
|----|---------------------------------|------:|------:|------:|-------:|
| 1  | Уточнение требований и MVP     |   …   |   …   |   …   |   …    |
| 2  | AS IS / TO BE сценарии         |   …   |   …   |   …   |   …    |
| …  | …                               |   …   |   …   |   …   |   …    |
| 10 | Тестирование, релиз, поддержка |   …   |   …   |   …   |   …    |

### 1.1.4. Итоговая длительность проекта

Суммарная трудоёмкость проекта:

Effort_total = Σ Te_avg(задача i) = XXX человеко-дней.

При размере команды k = N человек и равномерной загрузке Y FTE на человека
оценочная длительность проекта составила:

Project_duration_дни = Effort_total / (k · Y) = ZZZ рабочих дней,
Project_duration_месяцы ≈ ZZZ / 21 = MM месяцев.

Таким образом, по методу трёх точек ожидаемая длительность проекта по разработке
MVP FrameFinder составляет приблизительно MM месяцев при равномерной загрузке
команды.
